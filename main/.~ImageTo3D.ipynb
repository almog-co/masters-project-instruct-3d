{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c872d8c-8b56-472b-8105-f2a47448be68",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada236a-006a-4083-8df4-c4e42218ebdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import PIL\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget, decode_latent_mesh\n",
    "from shap_e.models.nn.camera import DifferentiableCameraBatch, DifferentiableProjectiveCamera\n",
    "from shap_e.util.image_util import load_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "assert(device != 'cuda')\n",
    "\n",
    "SAVE_LOCATION = 'models/'\n",
    "\n",
    "xm = load_model('transmitter', device=device)\n",
    "imageModel = load_model('image300M', device=device)\n",
    "textModel = load_model('text300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))\n",
    "\n",
    "def generateLatentImage(image, guidance_scale=3.0):\n",
    "    return generateLatent(dict(images=[image] * 1), imageModel, guidance_scale)\n",
    "\n",
    "def generateLatentPrompt(prompt, guidance_scale=15.0):\n",
    "    return generateLatent(dict(texts=[prompt] * 1), textModel, guidance_scale)\n",
    "\n",
    "def generateLatent(args, model, guidance_scale):\n",
    "    latents = sample_latents(\n",
    "        batch_size=1,\n",
    "        model=model,\n",
    "        diffusion=diffusion,\n",
    "        guidance_scale=guidance_scale,\n",
    "        model_kwargs=args,\n",
    "        progress=True,\n",
    "        clip_denoised=True,\n",
    "        use_fp16=True,\n",
    "        use_karras=True,\n",
    "        karras_steps=64,\n",
    "        sigma_min=1e-3,\n",
    "        sigma_max=160,\n",
    "        s_churn=0,\n",
    "    )\n",
    "    \n",
    "    return latents[0]\n",
    "\n",
    "def exportLatentToObj(latent, name):\n",
    "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "    with open(f'{SAVE_LOCATION}{name}.obj', 'w') as f:\n",
    "        t.write_obj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0f71f9-2939-4f3a-b90e-d6e3125ce5dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_single_pan_camera(\n",
    "    size: int,\n",
    "    device: torch.device,\n",
    "    theta: float) -> DifferentiableCameraBatch:\n",
    "    \n",
    "    # Convert theta from degrees to radians for trigonometric functions\n",
    "    theta_rad = np.radians(theta)\n",
    "    \n",
    "    # Calculate the camera's direction (z)\n",
    "    z = np.array([np.sin(theta_rad), np.cos(theta_rad), -0.5])\n",
    "    z /= np.linalg.norm(z)\n",
    "    \n",
    "    # Compute the camera's origin\n",
    "    origin = -z * 4\n",
    "    \n",
    "    # Compute the right (x) and up (y) vectors\n",
    "    x = np.array([np.cos(theta_rad), -np.sin(theta_rad), 0.0])\n",
    "    y = np.cross(z, x)\n",
    "    \n",
    "    # Reshape vectors to be 2D arrays with the second dimension of size 3\n",
    "    origin = origin.reshape(1, 3)\n",
    "    x = x.reshape(1, 3)\n",
    "    y = y.reshape(1, 3)\n",
    "    z = z.reshape(1, 3)\n",
    "    \n",
    "    # Create the DifferentiableCameraBatch object\n",
    "    return DifferentiableCameraBatch(\n",
    "        shape=(1, 1),\n",
    "        flat_camera=DifferentiableProjectiveCamera(\n",
    "            origin=torch.from_numpy(origin).float().to(device),\n",
    "            x=torch.from_numpy(x).float().to(device),\n",
    "            y=torch.from_numpy(y).float().to(device),\n",
    "            z=torch.from_numpy(z).float().to(device),\n",
    "            width=size,\n",
    "            height=size,\n",
    "            x_fov=0.7,\n",
    "            y_fov=0.7,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703b0b8-05d4-4361-aa6a-99e05def1679",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444e467-2dc8-4a2c-a92a-b3a2a59550fb",
   "metadata": {},
   "source": [
    "## Text To 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712cf58e-1529-4047-9eef-cbacede9657b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d30e497f0f4a67b1eb87ba590eda3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'An airplane'\n",
    "latent = generateLatentPrompt(title, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419b07-c63c-4a5b-8eff-52f0ea9d6843",
   "metadata": {},
   "source": [
    "## Image To 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2c6cafc-6166-45a6-9a3e-fd91bb487f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a42bda92330481e9e0d10ca7a935879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'An orange airplane - reconstructed'\n",
    "image = load_image(\"Images/an airplane.png\")\n",
    "latent = generateLatentImage(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fb418-164d-4ff2-9dff-8f03b11a7977",
   "metadata": {},
   "source": [
    "## Generate and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32d50338-4a73-46de-8fb7-52cac767bc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8d3179a9b47e1a5a1e2739c2d36ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhgACAAIcAAOexb+KqauioZd2vbdioauKlZdmlZ9akZNOkZsylaeWgXt2hZNâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2D Slice To: 2DSlice/An orange airplane - reconstructed\n",
      "Saved 3D Model To: models/An orange airplane - reconstructed\n"
     ]
    }
   ],
   "source": [
    "cameras = create_single_pan_camera(128, device, 60)\n",
    "images = decode_latent_images(xm, latent, cameras, rendering_mode='stf')\n",
    "display(gif_widget(images))\n",
    "images[0].save('2DSlice/' + title + '.png')\n",
    "print(f'Saved 2D Slice To: 2DSlice/{title}')\n",
    "\n",
    "exportLatentToObj(latent, title)\n",
    "print(f'Saved 3D Model To: {SAVE_LOCATION}{title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4c46e-808b-4686-941c-af3b35cbbdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
