{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25142ad-427d-462d-b854-4262f65a0438",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "The structure of the shared folder must be as follows:\n",
    "\n",
    "```\n",
    "shared\n",
    "│\n",
    "├── original_imgs --- 360 deg images of the original mesh\n",
    "│   └── fish.obj\n",
    "│       ├── 0.png\n",
    "│       ├── 1.png\n",
    "│       └── ...\n",
    "│\n",
    "├── original_meshes --- The original .obj files produced by Shap-E\n",
    "│   └── fish.obj\n",
    "│\n",
    "├── edited_imgs --- 360 deg images after being passed through Pix2Pix\n",
    "│   └── fish.obj - make it metallic\n",
    "│       ├── 0.png\n",
    "│       ├── 1.png\n",
    "│       └── ...\n",
    "│\n",
    "├── edited_meshes --- The reconstructed .obj files from the Pix2Pix edited_imgs\n",
    "│   └── fish.obj\n",
    "│\n",
    "└── alternate_meshes --- Alternative to running through Pix2Pix by re-prompting Shap-E\n",
    "    └── fish.obj\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3a5de7-b8c5-427e-b3ac-cee5c378fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHARED_FOLDER = r'C:\\Users\\Almog\\Dev\\shap-e\\project\\shared'\n",
    "\n",
    "# INSTRUCTIONS = {\n",
    "#     \"A houseplant\": \"make the plant metallic\",\n",
    "#     \"An apple\": \"turn the apple into a crystal\",\n",
    "#     \"A coffee mug\": \"turn the mug into a bowl\",\n",
    "#     \"A bicycle\": \"make the bicycle wooden\",\n",
    "#     \"An office chair\": \"turn the office chair into a velvet style\",\n",
    "#     \"A notebook\": \"turn the notebook into leather\",\n",
    "#     \"An umbrella\": \"make umbrella minecraft style\",\n",
    "#     \"A wristwatch\": \"make the watch gold\",\n",
    "#     \"A pair of shoes\": \"make the shoes rubber\",\n",
    "#     \"A toothbrush\": \"make the toothbrush into bamboo\",\n",
    "#     \"A teapot\": \"make the teapot out of silver\",\n",
    "#     \"A backpack\": \"turn the backpack into denim\",\n",
    "#     \"A smartphone\": \"make the smartphone plastic\",\n",
    "#     \"A desk lamp\": \"add brass to the desk lamp\",\n",
    "#     \"A water bottle\": \"make the water bottle out of legos\"\n",
    "# }\n",
    "\n",
    "INSTRUCTIONS = {\n",
    "    \"a cheeseburger\": \"Make the bun out of chocolate\",\n",
    "    \"an apple\": \"Transform the apple into a green delicious apple\",\n",
    "    \"a traffic cone\": \"Give the traffic cone a futuristic, neon-light design\",\n",
    "    \"a pumpkin\": \"Carve a spooky face on the pumpkin\",\n",
    "    \"a banana\": \"Add chocolate syrup\",\n",
    "    \"a water bottle\": \"Give the water bottle a metallic finish\",\n",
    "    \"a golden retriever dog\": \"Turn the dog into a husky breed\",\n",
    "    \"a birthday cake\": \"Add a lot of birthday candles to the brithday cake\",\n",
    "    \"a red couch\": \"Make the couch into lego\",\n",
    "    \"a rubber duck\": \"Make the rubber duck minecraft style\"\n",
    "}\n",
    "\n",
    "INSTRUCTIONS = {\n",
    "   \"an apple\": \"Make the apple plaid\",\n",
    "}\n",
    "\n",
    "PROMPTS = []\n",
    "EDITED_INSTRUCTIONS = []\n",
    "\n",
    "for prompt, instruction in INSTRUCTIONS.items():\n",
    "    PROMPTS.append(prompt)\n",
    "    EDITED_INSTRUCTIONS.append(instruction)\n",
    "\n",
    "COMBINED_PROMPTS = [\n",
    "    \"A chocolate and candy cheeseburger\",\n",
    "    \"A green delicious apple\",\n",
    "    \"A futuristic, neon-light designed traffic cone\",\n",
    "    \"A pumpkin with a spooky carved face\",\n",
    "    \"A banana with whipped cream and chocolate syrup\",\n",
    "    \"A water bottle with a metallic finish\",\n",
    "    \"A husky breed dog\",\n",
    "    \"A birthday cake with birthday candles\",\n",
    "    \"A red couch with cushions on top\",\n",
    "    \"A Minecraft-style rubber duck\",\n",
    "]\n",
    "\n",
    "GUIDANCE_SCALE = 15.0\n",
    "TRIAL = False\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "assert(device != 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac05c0-0792-4c57-8015-0cd3a07f5d3e",
   "metadata": {},
   "source": [
    "# Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d07b0-1024-4c36-84ab-e25995917ea9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1078809-e9df-4216-a4c7-a351e3ba99b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget, decode_latent_mesh\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "assert(device != 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bc6c46-efcd-4650-afdd-d564b61099d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmModel = load_model('transmitter', device=device)\n",
    "textModel = load_model('text300M', device=device)\n",
    "diffusionModel = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a021a-c7f5-474d-bb42-9a8aeb891baf",
   "metadata": {},
   "source": [
    "## Generate and Save .OBJ Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3af50c-9f9b-4c8c-ac4a-106ebc82bd0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90b3b23a75f440dbff6886fc6d312ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb3ab28a51b461f9ec4f159b014102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64a458091464f57a2f923a5199adf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4673aa227227453d8d3debf247ac52cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb898a538b5a4148a79d156d3c198cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c68ddc89f564408afac5e95480edb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f86677040483dbb683091af71b90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72ea19601aa4770b5aabdb43b40c5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faca35cf41754701a1e8145e6e6ffb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf98091f551405da63a87e9b146fabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'original_meshes')\n",
    "\n",
    "latents = []\n",
    "for prompt in PROMPTS:\n",
    "    \n",
    "    # Generate a text-to-3d latent representations\n",
    "    latent = sample_latents(\n",
    "        batch_size=1,\n",
    "        model=textModel,\n",
    "        diffusion=diffusionModel,\n",
    "        guidance_scale=GUIDANCE_SCALE,\n",
    "        model_kwargs=dict(texts=[prompt]),\n",
    "        progress=True,\n",
    "        clip_denoised=True,\n",
    "        use_fp16=True,\n",
    "        use_karras=True,\n",
    "        karras_steps=128, # Originally 64\n",
    "        sigma_min=1e-3,\n",
    "        sigma_max=160,\n",
    "        s_churn=0,\n",
    "    )[0]\n",
    "    latents.append(latent)\n",
    "    # mesh = decode_latent_mesh(xmModel, latent).tri_mesh()\n",
    "    # try:\n",
    "    #     with open(os.path.join(folder, f'{prompt}.obj'), 'w') as f:\n",
    "    #         mesh.write_obj(f)\n",
    "    #         print(f'Successfully saved \"{prompt}.obj\".')\n",
    "    # except IOError as e:\n",
    "    #     print(f'Failed to save \"{prompt}.obj\".')\n",
    "        \n",
    "    if TRIAL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83513e8f-f698-4a31-9b2c-a44ebbe89db1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate 1 View from Latent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1e515-148f-4bc0-b161-5f9ae7ce61ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9347286-3196-44ff-8a72-c0afbf17da67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shap_e.models.nn.camera import DifferentiableCameraBatch, DifferentiableProjectiveCamera\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edca0cb8-3b0b-4539-b19f-05654678dc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_single_pan_camera(\n",
    "    size: int,\n",
    "    device: torch.device,\n",
    "    theta: float) -> DifferentiableCameraBatch:\n",
    "    \n",
    "    # Convert theta from degrees to radians for trigonometric functions\n",
    "    theta_rad = np.radians(theta)\n",
    "    \n",
    "    # Calculate the camera's direction (z)\n",
    "    z = np.array([np.sin(theta_rad), np.cos(theta_rad), -0.5])\n",
    "    z /= np.linalg.norm(z)\n",
    "    \n",
    "    # Compute the camera's origin\n",
    "    origin = -z * 4\n",
    "    \n",
    "    # Compute the right (x) and up (y) vectors\n",
    "    x = np.array([np.cos(theta_rad), -np.sin(theta_rad), 0.0])\n",
    "    y = np.cross(z, x)\n",
    "    \n",
    "    # Reshape vectors to be 2D arrays with the second dimension of size 3\n",
    "    origin = origin.reshape(1, 3)\n",
    "    x = x.reshape(1, 3)\n",
    "    y = y.reshape(1, 3)\n",
    "    z = z.reshape(1, 3)\n",
    "    \n",
    "    # Create the DifferentiableCameraBatch object\n",
    "    return DifferentiableCameraBatch(\n",
    "        shape=(1, 1),\n",
    "        flat_camera=DifferentiableProjectiveCamera(\n",
    "            origin=torch.from_numpy(origin).float().to(device),\n",
    "            x=torch.from_numpy(x).float().to(device),\n",
    "            y=torch.from_numpy(y).float().to(device),\n",
    "            z=torch.from_numpy(z).float().to(device),\n",
    "            width=size,\n",
    "            height=size,\n",
    "            x_fov=0.7,\n",
    "            y_fov=0.7,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556787bb-e5b7-4714-852e-f28b9a0e4551",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a93b9b6e-8b02-4041-86d5-4488f940e538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a cheeseburger.obj\\0.png\n",
      "Saved an apple.obj\\0.png\n",
      "Saved a traffic cone.obj\\0.png\n",
      "Saved a pumpkin.obj\\0.png\n",
      "Saved a banana.obj\\0.png\n",
      "Saved a water bottle.obj\\0.png\n",
      "Saved a golden retriever dog.obj\\0.png\n",
      "Saved a birthday cake.obj\\0.png\n",
      "Saved a red couch.obj\\0.png\n",
      "Saved a rubber duck.obj\\0.png\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'original_imgs_512')\n",
    "\n",
    "for prompt, latent in zip(PROMPTS, latents):\n",
    "    cameras = create_single_pan_camera(512, device, 15)\n",
    "    imgs = decode_latent_images(xmModel, latent, cameras, rendering_mode='stf')\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        # Make the folder for each prompt\n",
    "        if not os.path.isdir(os.path.join(folder, f'{prompt}.obj')):\n",
    "            os.mkdir(os.path.join(folder, f'{prompt}.obj'))\n",
    "            \n",
    "        img.save(os.path.join(folder, f'{prompt}.obj\\{i}.png'))\n",
    "        print(f'Saved {prompt}.obj\\{i}.png')\n",
    "        \n",
    "    if TRIAL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06661e69-8254-42fe-bb46-0265d3ecedf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate 360 Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f231fb-0193-4216-9579-d28892bc93dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89838326-f1e8-4acd-94c0-3a9d854dd89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Viewer3D.Viewer3D as Viewer3D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ce829-9f94-4220-8a36-2da604c2285b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate and Save .PNG Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9769c361-5fa8-493d-9899-353dd3346ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'original_imgs')\n",
    "\n",
    "for prompt in PROMPTS:\n",
    "    mesh_folder = os.path.join(SHARED_FOLDER, 'original_meshes')\n",
    "    mesh_filename = os.path.join(mesh_folder, f'{prompt}.obj')\n",
    "    imgs = Viewer3D.generateImagesTriMesh(mesh_filename)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        # Make the folder for each prompt\n",
    "        if not os.path.isdir(os.path.join(folder, f'{prompt}.obj')):\n",
    "            os.mkdir(os.path.join(folder, f'{prompt}.obj'))\n",
    "            \n",
    "        img.save(os.path.join(folder, f'{prompt}.obj\\{i}.png'))\n",
    "        \n",
    "        if TRIAL:\n",
    "            display(img.convert(\"RGB\"))\n",
    "    if TRIAL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca05e1e-98a9-4205-8f06-11e33281b057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Meshes Directly w/ Edit Instructions\n",
    "\n",
    "Make make sure to run the setup in the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef29b868-f842-400a-9e0a-7f8dccb978bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1777592c11d344da8c80374d578737a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A chocolate and candy cheeseburger.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0edac9ddda49aba96952459529d783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A green delicious apple.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd08ef5ddb04178a5b56a4238993ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A futuristic, neon-light designed traffic cone.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7d643f1b748ffad41f70986d18dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A pumpkin with a spooky carved face.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dd76a1fa2841f6a953fba5e7730ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A banana with whipped cream and chocolate syrup.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c2cd3b8cb54dfb8bfdc2c72f32acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A water bottle with a metallic finish.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f70b149f684f47bb2376eb2c61b203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A husky breed dog.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461950fc5cb447fab09c738c8219c676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A birthday cake with birthday candles.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da193a7dc2f54ebb906ab61db9b2c692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A red couch with cushions on top.obj\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc66444f39249008fb5e0908f975762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"A Minecraft-style rubber duck.obj\".\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'alternate_meshes')\n",
    "for prompt in COMBINED_PROMPTS:\n",
    "    \n",
    "    # Generate a text-to-3d latent representations\n",
    "    latent = sample_latents(\n",
    "        batch_size=1,\n",
    "        model=textModel,\n",
    "        diffusion=diffusionModel,\n",
    "        guidance_scale=GUIDANCE_SCALE,\n",
    "        model_kwargs=dict(texts=[prompt]),\n",
    "        progress=True,\n",
    "        clip_denoised=True,\n",
    "        use_fp16=True,\n",
    "        use_karras=True,\n",
    "        karras_steps=128, # Originally 64\n",
    "        sigma_min=1e-3,\n",
    "        sigma_max=160,\n",
    "        s_churn=0,\n",
    "    )[0]\n",
    "    \n",
    "    mesh = decode_latent_mesh(xmModel, latent).tri_mesh()\n",
    "    try:\n",
    "        with open(os.path.join(folder, f'{prompt}.obj'), 'w') as f:\n",
    "            mesh.write_obj(f)\n",
    "            print(f'Successfully saved \"{prompt}.obj\".')\n",
    "    except IOError as e:\n",
    "        print(f'Failed to save \"{prompt}.obj\".')\n",
    "        \n",
    "    if TRIAL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87de9a-a0e2-4cb9-89d4-91287909fde4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine Images Into 3D Mesh\n",
    "\n",
    "Takes images from `edited_imgs` and produces `edited_meshes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e410c-9afe-44fe-88cb-cd2ce3943ac7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b36610d6-cd22-4535-94f8-d0e1f90c4309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget, decode_latent_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a577d3fc-ff10-4449-a964-c7b8237c9b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmModel = load_model('transmitter', device=device)\n",
    "imageModel = load_model('image300M', device=device)\n",
    "diffusionModel = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679d282-a680-4c8d-b089-7ec761ade097",
   "metadata": {},
   "source": [
    "## Generate 3D Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1424a048-978b-4702-bf8d-8d4017067acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Almog\\Dev\\shap-e\\project\\shared\\edited_masked_imgs_512\\an apple.obj - Make the apple plaid\\0.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e089959e717a4c65800e0cb47c991568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"an apple - Make the apple plaid.obj\".\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'edited_meshes')\n",
    "\n",
    "guidance_scale = 3.0\n",
    "\n",
    "for imgs_foldername in [f'{prompt}.obj - {instruction}' for prompt, instruction in zip(PROMPTS, EDITED_INSTRUCTIONS)]:\n",
    "    imgs_folder_path = os.path.join(SHARED_FOLDER, f'edited_masked_imgs_512\\{imgs_foldername}')\n",
    "    if not os.path.exists(imgs_folder_path):\n",
    "        continue\n",
    "            \n",
    "    for img_filename in [f for f in os.listdir(imgs_folder_path) if '.png' in f]:\n",
    "        fullpath = os.path.join(imgs_folder_path, img_filename)\n",
    "        print(fullpath)\n",
    "        \n",
    "        image = load_image(fullpath)\n",
    "        \n",
    "        latent = sample_latents(\n",
    "            batch_size=1,\n",
    "            model=imageModel,\n",
    "            diffusion=diffusionModel,\n",
    "            guidance_scale=guidance_scale,\n",
    "            model_kwargs=dict(images=[image]),\n",
    "            progress=True,\n",
    "            clip_denoised=True,\n",
    "            use_fp16=True,\n",
    "            use_karras=True,\n",
    "            karras_steps=128,  # originally 64\n",
    "            sigma_min=1e-3,\n",
    "            sigma_max=160,\n",
    "            s_churn=0,\n",
    "        )[0]\n",
    "        \n",
    "        mesh = decode_latent_mesh(xmModel, latent).tri_mesh()\n",
    "        output_filename = imgs_foldername.replace('.obj', '') + '.obj'\n",
    "        try:\n",
    "            with open(os.path.join(folder, output_filename), 'w') as f:\n",
    "                mesh.write_obj(f)\n",
    "                print(f'Successfully saved \"{output_filename}\".')\n",
    "        except IOError as e:\n",
    "            print(f'Failed to save \"{output_filename}\".')\n",
    "        \n",
    "        # Breaking b/c can't figure out how to combine the multiple images into a 3D model\n",
    "        # So doing only 1 prespective. Future Work!\n",
    "        break\n",
    "    \n",
    "    if TRIAL:\n",
    "        break\n",
    "\n",
    "        folder = os.path.join(SHARED_FOLDER, 'original_reconstructed_meshes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010b7bc-134c-4c00-88f1-a5878ace02a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine Original Images Into 3D Mesh\n",
    "\n",
    "Takes images from `edited_imgs` and produces `edited_meshes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a264a-a766-4261-9d81-53abd6dd80fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e12572d-e91a-493a-b1ca-f78c729e2a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget, decode_latent_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3013d3a-e349-4976-81ec-1f810382c21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmModel = load_model('transmitter', device=device)\n",
    "imageModel = load_model('image300M', device=device)\n",
    "diffusionModel = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1b9ab-98c7-40b0-b8ea-627cef43363b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate 3D Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35459f6-fedb-455e-89fa-9a915281f803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Almog\\Dev\\shap-e\\project\\shared\\original_imgs\\a birthday cake.obj\\0.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de631ed7326343f4a16bddcfb2a68b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"a birthday cake.obj\".\n",
      "C:\\Users\\Almog\\Dev\\shap-e\\project\\shared\\original_imgs\\a red couch.obj\\0.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5539520470455bbc3a2c7b918146d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"a red couch.obj\".\n",
      "C:\\Users\\Almog\\Dev\\shap-e\\project\\shared\\original_imgs\\a rubber duck.obj\\0.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8c178cf6564c1d90ff6b899b4d078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved \"a rubber duck.obj\".\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join(SHARED_FOLDER, 'original_reconstructed_meshes')\n",
    "guidance_scale = 3.0\n",
    "\n",
    "for imgs_foldername in [f'{prompt}.obj' for prompt in PROMPTS]:\n",
    "    imgs_folder_path = os.path.join(SHARED_FOLDER, f'original_imgs\\{imgs_foldername}')\n",
    "    if not os.path.exists(imgs_folder_path):\n",
    "        continue\n",
    "            \n",
    "    for img_filename in [f for f in os.listdir(imgs_folder_path) if '.png' in f]:\n",
    "        fullpath = os.path.join(imgs_folder_path, img_filename)\n",
    "        print(fullpath)\n",
    "        \n",
    "        image = load_image(fullpath)\n",
    "        \n",
    "        latent = sample_latents(\n",
    "            batch_size=1,\n",
    "            model=imageModel,\n",
    "            diffusion=diffusionModel,\n",
    "            guidance_scale=guidance_scale,\n",
    "            model_kwargs=dict(images=[image]),\n",
    "            progress=True,\n",
    "            clip_denoised=True,\n",
    "            use_fp16=True,\n",
    "            use_karras=True,\n",
    "            karras_steps=128,  # originally 64\n",
    "            sigma_min=1e-3,\n",
    "            sigma_max=160,\n",
    "            s_churn=0,\n",
    "        )[0]\n",
    "        \n",
    "        mesh = decode_latent_mesh(xmModel, latent).tri_mesh()\n",
    "        output_filename = imgs_foldername.replace('.obj', '') + '.obj'\n",
    "        try:\n",
    "            with open(os.path.join(folder, output_filename), 'w') as f:\n",
    "                mesh.write_obj(f)\n",
    "                print(f'Successfully saved \"{output_filename}\".')\n",
    "        except IOError as e:\n",
    "            print(f'Failed to save \"{output_filename}\".')\n",
    "        \n",
    "        # Breaking b/c can't figure out how to combine the multiple images into a 3D model\n",
    "        # So doing only 1 prespective. Future Work!\n",
    "        break\n",
    "    \n",
    "    if TRIAL:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121ed34-bbfb-4729-8cd3-26a2a42bc25c",
   "metadata": {},
   "source": [
    "# Mask The Original Images and Apply to Edited Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a45856b7-8108-4c24-b677-0323f72e88d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c71c341-95d3-4808-b099-fc12ce6ec9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking a banana.obj - Add chocolate syrup/0.png\n",
      "Masking a birthday cake.obj - Add a lot of birthday candles to the brithday cake/0.png\n",
      "Masking a cheeseburger.obj - Make the bun out of chocolate/0.png\n",
      "Masking a golden retriever dog.obj - Turn the dog into a husky breed/0.png\n",
      "Masking a pumpkin.obj - Carve a spooky face on the pumpkin/0.png\n",
      "Masking a red couch.obj - Make the couch into lego/0.png\n",
      "Masking a red couch.obj - Place couch cushions on top of the couch/0.png\n",
      "Masking a rubber duck.obj - Make the rubber duck minecraft style/0.png\n",
      "Masking a water bottle.obj - Give the water bottle a metallic finish/0.png\n",
      "Masking an apple.obj - Make the apple plaid/0.png\n",
      "Masking an apple.obj - Transform the apple into a green delicious apple/0.png\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_IMGS = os.path.join(SHARED_FOLDER, 'edited_masked_imgs_512')\n",
    "ORIGINAL_IMGS = os.path.join(SHARED_FOLDER, 'original_imgs_512')\n",
    "EDITED_IMGS = os.path.join(SHARED_FOLDER, 'edited_imgs_512')\n",
    "\n",
    "for folder_name in os.listdir(EDITED_IMGS):\n",
    "    if not os.path.exists(os.path.join(ORIGINAL_IMGS, folder_name.split(' - ')[0])):\n",
    "        print(f'Skipping {folder_name}')\n",
    "        continue\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(EDITED_IMGS, folder_name)):\n",
    "        full_org_img_path = os.path.join(os.path.join(ORIGINAL_IMGS, folder_name.split(' - ')[0]), img_name)\n",
    "        full_edit_img_path = os.path.join(os.path.join(EDITED_IMGS, folder_name), img_name)\n",
    "\n",
    "        if not os.path.exists(full_org_img_path):\n",
    "            print(f'Skipping {folder_name}/{img_name}')\n",
    "            continue\n",
    "        \n",
    "        print(f'Masking {folder_name}/{img_name}')\n",
    "        \n",
    "        org_img = cv2.imread(full_org_img_path)\n",
    "        org_gray = cv2.cvtColor(org_img, cv2.COLOR_BGR2GRAY)\n",
    "        _, org_mask = cv2.threshold(org_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "        org_contours, _ = cv2.findContours(org_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        org_contours = [sorted(org_contours, key=cv2.contourArea, reverse=True)[1]]\n",
    "        \n",
    "        edit_img = cv2.imread(full_edit_img_path)\n",
    "        \n",
    "        new_img = np.zeros_like(org_img, dtype=np.uint8)\n",
    "        cv2.drawContours(new_img, org_contours, -1, (255, 255, 255), -1)\n",
    "        region = cv2.bitwise_and(edit_img, new_img)\n",
    "        new_img[new_img != 0] = region[new_img != 0]\n",
    "        \n",
    "        # cv2.imshow('New Image', new_img)\n",
    "        # cv2.waitKey(0)\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(OUTPUT_IMGS, folder_name)):\n",
    "            os.mkdir(os.path.join(OUTPUT_IMGS, folder_name))\n",
    "        cv2.imwrite(os.path.join(os.path.join(OUTPUT_IMGS, folder_name), img_name), new_img)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d074260-ebad-45d4-8c27-567366f10b43",
   "metadata": {},
   "source": [
    "# Apply InstructPix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f4c6ee-b3fa-498f-a710-c254c7ba8798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7f1435-9437-47a8-a733-f9f3ee70549d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73a93c7ba1d463ab39d25dab8602c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,    \n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b057f6a-8b09-4f92-8c6f-c4b307460eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running C:\\Users\\Almog\\Dev\\shap-e\\project\\shared\\original_imgs_512\\an apple.obj\\0.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adafa8c32eb464c83ead84b993c490e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ORIGINAL_IMGS_DIR = os.path.join(SHARED_FOLDER, 'original_imgs_512')\n",
    "EDITED_IMGS_DIR = os.path.join(SHARED_FOLDER, 'edited_imgs_512')\n",
    "\n",
    "RESOLUTION = 512\n",
    "STEPS = 100\n",
    "CFG_TEXT = 11.5  # Default is 7.5\n",
    "CFG_IMAGE = 3.5 # Default is 1.5\n",
    "\n",
    "os.makedirs(EDITED_IMGS_DIR, exist_ok=True)\n",
    "\n",
    "for i, folder in enumerate(os.listdir(ORIGINAL_IMGS_DIR)):\n",
    "    if not 'apple' in folder:\n",
    "        continue\n",
    "    folder_path = os.path.join(ORIGINAL_IMGS_DIR, folder)\n",
    "    if folder == '.ipynb_checkpoints' or not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    edited_instruction = INSTRUCTIONS[folder.replace('.obj', '')]\n",
    "\n",
    "    # Create a corresponding folder in edited images directory\n",
    "    edited_folder_path = os.path.join(EDITED_IMGS_DIR, f'{folder} - {edited_instruction}')\n",
    "    os.makedirs(edited_folder_path, exist_ok=True)\n",
    "    \n",
    "    if 'traffic' in folder:\n",
    "        print('Skipping Cone...')\n",
    "        continue\n",
    "\n",
    "    # Iterate over each image in the folder\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "        \n",
    "        print(f'Running {img_path}')\n",
    "        org_img = Image.open(img_path)\n",
    "        output_path = os.path.join(edited_folder_path, img_file)\n",
    "        edit_img = pipe(\n",
    "            edited_instruction,\n",
    "            image=org_img,\n",
    "            image_guidance_scale=CFG_IMAGE,\n",
    "            guidance_scale=CFG_TEXT,\n",
    "            num_inference_steps=STEPS\n",
    "        ).images[0]\n",
    "        edit_img.save(output_path)\n",
    "        \n",
    "        # Future Work: Support for many images\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2e9d1-91cd-489a-991e-9abfca35360c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
